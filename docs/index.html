<!DOCTYPE HTML>
<!--
	Dimension by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Project 6</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
						<div class="logo">
							<span class="icon fa-users"></span>
						</div>
						<div class="content">
							<div class="inner">
								<h1>Facial emotion recognition based on mouth analysis</h1>
								<h3 class="desc">Description of our project</h3>
								<p class="desc"><b>Input:</b> videos or static color images of a persons’ face, under natural conditions; good lighting, but, no makeup! <br>
<b>Objective:</b> recognize emotional state using mouth information; useful for computer tutoring systems. Mouth must be located first
<br><b>Tasks to do:</b>
find the mouth region in a facial image (relatively of known position and size, assume you’re in front of a computer and you have a webcam) 
analyze the mouth shape and state – find suitable descriptors for it, in order to accurately classify different emotions
at least basic emotions should be identified (i.e. neutral, happy, sad, surprised) but also some spontaneous emotion would be nice
<br><b>Output:</b> the mouth identified and the emotion recognized
<br><b>Remarks:</b> 
difficulty – high; 
Any suggestions as of how could one distinguish from video only between mouth change during speech and emotion?
 <a href="https://ssip2018.medunigraz.at/">Source</a> of description.</p>
							</div>
						</div>
						<nav>
							<ul>
								<li><a href="#intro">Task</a></li>
								<li><a href="#data">Dataset</a></li>
								<li><a href="#features">Features</a></li>
                                <li><a href="#program">Program</a></li>
								<li><a href="#stats">Statistics</a></li>
								<li><a href="#members">Members</a></li>
								
								<!--<li><a href="#elements">Elements</a></li>-->
							</ul>
						</nav>
					</header>

				<!-- Main -->
					<div id="main">

						<!-- Intro -->
							<article id="intro">
								<h2 class="major">Task</h2>
								<p><b>Idea and approach</b><br>
Main idea was to find mouth on image and try to use convolutional neural network to classify emotions on images. However, lack of data and short deadlines changed approach to something simpler. It was decided to use landmarks of characteristic parts of mouth and based on features that was extracted from those landmarks classify emotions with some simpler methods such as Random forest, Naive Bayes, Decision Tree and K-Nearest Neighbour. 
                            <br></p>
                            <p><b>Workflow</b><br>
                            Project workflow main steps:
    <ul>
                            <li>Collecting the dataset</li>
                            <li>Detect mouth landmarks</li>
                            <li>Feature extracting</li>
                            <li>Training the alghorithm</li>
                            <li>Statistic evaluation on algorithms</li>
                            <li>Building application</li>
                            </ul>
                    
                            <span class="image main"><img src="images/task/workflow.png" alt="workflow" /></span>

</p>
							</article>
                        
                        <!-- Dataset -->
							<article id="data">
								<h2 class="major">Dataset</h2>
								<p>First step in workflow was to gather data for algorithm training. This task was done in two different steps:
                                <ol>
                                <li>Searching and downloading existing datasets that contains face images and emotion labels.</li>
                                <li>Manually searching and labeling images.</li>
                                </ol>
                                <b>Existing datasets</b>
                                <br>There are several existing datasets that contains face images and emotion labels for them, yet only one dataset was available  to download for free. Available dataset can be downloaded from the following <a href="http://cseweb.ucsd.edu/~gary/CAFE/">website</a> .
It contains 139 labeled images in eight emotions categories. Among that categories are also 4 categories that are detected in this project:
                                <ul>
                                <li>Anger</li>
                                <li>Happiness</li>
                                <li>Sadness</li>
                                <li>Normal resting face</li>
                                </ul>                                
								<span class="image main"><img src="images/dataset/37-35-40.png" alt="" /></span>
								After removing images that doesn’t contain required emotions only 90 images was left from this dataset. Since this number of images was not enough, other images were needed to be acquired manually. 
                                </p>                            
								<p><b>Manually searching and labeling images</b><br>
								With process of manually searching and labeling images another 110 pictures were collected making projects dataset contains 200 images in total. Process of manually searching and labeling images is simple but laborious: seeking for images on google, downloading them and correctly labeling them. 
								                                
								<span class="image main"><img src="images/dataset/faces.jpg" alt="" /></span>
								</p>
							</article>
							
                        <!-- Features -->
							<article id="features">
								<h2 class="major">Features</h2>
								<p><b>Mouth detection</b><br>Mouth detection is a crucial part of this project. After searching the web, we agreed to use face recognition with 68 landmarks from dlib library.		
								<span class="image main"><img src="images/features/landmarks.jpg" alt="" /></span>
								Dlib library uses Histogram of Oriented gradients algorithm which was trained on <a href="https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/">iBUG 300-W dataset</a>. More about histogram of oriented gradients can be found <a href="http://mccormickml.com/2013/05/09/hog-person-detector-tutorial/">here</a>. After detection of all 68 landmarks, only landmarks from 48 to 68 were recorded because those landmarks describe mouth. Next step is to see how this 20 landmarks describe each emotion and extract features that do the best distinguish between them.  							
								</p>
								<p><b>Features</b>
								<ol>
                                <li>Area - detect opened mouth <span class="image main"><img src="images/features/2_Area_mouth_box2.png" alt="" /></span></li>
                                <li>MSE - detect opened mouth <span class="image main"><img src="images/features/3_MSE_open_mouth.png" alt="" /></span></li>
                                <li>Curvativie 1. - detect smile mouth  <span class="image main"><img src="images/features/4_curvature1_smile.png" alt="" /></span></li>
                                <li>Curvativie 2. - detect sad mouth  <span class="image main"><img src="images/features/5_curvature2_sad.png" alt="" /></span></li>
                                <li>Corners - detect corners for neutral or sad  <span class="image main"><img src="images/features/6_corners_neutral-sad.png" alt="" /></span></li>
                                <li>General shape - detect sad or neutral or angry <span class="image main"><img src="images/features/7_general_shape_sad-neutral-angry.png" alt="" /></span></li>
                                <li>Scaled distances - detect distances <span class="image main"><img src="images/features/8_distances_scale.png" alt="" /></span></li>
								</ol>
								Based on this features, algorithm were trained.
								</p>
							</article>
                        
						<!-- Program -->
							<article id="program">
								<h2 class="major">Program</h2>
								<span class="image left"><img src="images/program/pycon.png" alt="" /></span>
								<p>All coding in this project was done in program language Python (v 2.7.12). Main reason is that Dlib library for mouth feature extraction is supported in Python, C and C++ program languages. Taking into consideration short project deadline, Python was better choice than C and C++. (All source code is available at link)<br><br><br>During the project several program scripts were created:
                                <ol>
                                <li>webcamDetector.py</li>
                                <li>extractFeatures.py</li>
                                <li>trainAlgorithms.py</li>
                                <li>testIt.py</li>
                                <li>statistics.py</li>
                                <li>confusionPlot.py</li>
                                </ol></p>
                                <p><b>webcamDetector.py</b><br>
                                This is the main application of project that uses all knowledge that project provided. Main goal of this application is to detect emotions of multiple humans from real time webcam stream. Application requires tree files: 
                                <ol>
                                <li>“features.txt” - file containing features for detection algorithm training</li>
                                <li>“labels.csv”- file containing labels for detection algorithm training</li>
                                <li>“shape_predictor_68_face_landmarks.dat” - file conating landmarks for mouth detection</li>
                                </ol>
                                <span class="image main"><img src="images/program/h-s-n-a.png" alt="" /></span>
                                </p>                                
								<p class="desc"><b>extractFeatures.py</b><br>This script generate “features.txt” file. It uses images as input, detect mouth on them and then calculate features of the mouth. Features are saved to file for each image in one line separated by commas. Script requires file “shape_predictor_68_face_landmarks.dat”.
								</p>
								<p><b>trainAlgorithms.py</b><br>This script trains algorithms and writes statistics. Algorithms trained are Random forest, Decision tree, Naive Bayes and K-nearest neighbours. Their performances are averaged on 100 tests on dataset that is splitted in ratio 80:20 (training:test). Also performance statistic is  written for each and every algorithm. Script requires “features.txt” and “labels.csv” files.
								</p>
								<p><b>testIt.py</b><br>This is a simple application to test human performance on images of mouths. Input files are images, emotion labels for images and “shape_predictor_68_face_landmarks.dat” file. Application crops the mouth from the image, displays it to the subject and writes his answer to simple “&lt;number of tester&gt;.csv” file. Answers are separated by commas. The correct answers for the images are written in first line of file.
								</p>
								<p><b>statistics.py</b><br>This scripts takes subjects’ and machines’ answers and generate confusion matrices for them. Subjects’ answers are provided in the “.csv” files generated by the “testIt.py” script. However machines’ answers are calculated ad hoc (“features.txt” and  “labels.txt” files must be provided).
								</p>
								<p><b>confusionPlot.py</b><br>This script plots provided confusion matrix.</p>
							</article>

						<!-- Statistics -->
							<article id="stats">
								<h2 class="major">Statistics and conclusion</h2>
								<h3>Statistics</h3>
								<p>There are two major statistical evaluations in this project:
								<ol>
								<li>Evaluation of the algorithms.</li>
								<li>Evaluation between subjects’ performance and machines’ performance.</li>
								</ol>
								</p>
								<p><b>Evaluation of the algorithms</b><br>
								Script “trainAlgorithms.py” provides accuarcy for each of the four trained algorithms:
Random forest, Decision tree, K-nearest neighbours and Naive Bayes. Following graph provides their average results 100 training cycles:
                                <span class="image main"><img src="images/stats/TreningAlghoritms.jpg" alt=""/></span>
								As it can be noticed, the best algorithm is Random forest. Therefore, Random forest is used in webcamDetector application and for further evaluation against subjects’ performance. Confusion matrix for Random forest algorithm is shown on next graph:
								 <span class="image main"><img src="images/stats/TrainingCF.png" alt=""/></span>
								</p>
								<p><b>Evaluation between subjects’ performance and machines’ performance</b><br>
								Evaluation between subjects’ performance and machines’ performance is done between 7 test subjects on 19 images that express all 4 different emotions and Random forest algorithm that was previously trained. In next histogram it is shown that subjects performed roughly 6% better than the machine. 
                                <span class="image main"><img src="images/stats/Machine-Human.jpg" alt=""/></span>
                                Also here are confusion matrices for subjects’ performance and machines’ performance:
                                <span class="image main"><img src="images/stats/humanCF.png" alt=""/></span>
                                <span class="image main"><img src="images/stats/algCF.png" alt=""/></span>
								</p>
								<p><h3>Conclusion</h3>
								There are three reasons why algorithm did not perform well:
								<ul>
								<li>Small dataset, probably if dataset was bigger, algorithm will generalise better.</li>
                                <li>Task is really hard, even human struggled on detecting emotion from the mouth images.</li>
                                <li>Features that are describing mouth are made up really quickly and on spot. Therefore, there might be some other features that will distinguish between emotions even better.</li>
								</ul>
								Sad:  <span class="image main"><img src="images/stats/Face-Mouth_1.jpg" alt=""/></span>
								Angry: <span class="image main"><img src="images/stats/Face-Mouth_2.jpg" alt=""/></span>
								</p>
								<p><h2>Futurework</h2>
								To improve detection of emotions based on mouth shape it is important to gather more data and extract features that are based not only on shape but also on the colour. Convolutional neural network could be a good solution. Also proposed solution for problem to detect emotion for talking person lays into measuring emotions during several frames of video and than calculate average emotion. People never use emotion only for a glimpse of a second.
								</p>
							</article>

                        <!-- Members -->
							<article id="members">
								<h2 class="major">Members</h2>
								<div class="newLine">
								<span class="image left"><img src="images/members/franko.jpg" alt="" /></span>
								<p><br><b>Franko Hržić</b>
								<br>
								<br>University of Rijeka Faculty of Engineering
								<br>Mag.ing.comp.
                                <br>fhrzic@riteh.hr
								</p>								
								</div>
								
								<div class="newLine">
								<span class="image right"><img src="images/members/martin.jpg" alt="" /></span>
								<p><br><b>Martin Polzhofer</b>
								<br>Medical University of Graz
                                <br>martin(dot)polzhofer[at]stud.medunigraz.at </p>
								</div>
								
								<div class="newLine">
								<span class="image left"><img src="images/members/silvester.jpg" alt="" /></span>
								<p><br><b>Szilveszter Domany</b>
								<br>University of Szeged, Hungary
								<br>Computer Science MSc
								<br>Domany(dot)Szilveszter[at]stud.u-szeged.hu</p>
								</div>
							</article>
							
						<!-- Contact -->
							<article id="contact">
								<h2 class="major">Contact</h2>
								<form method="post" action="#">
									<div class="fields">
										<div class="field half">
											<label for="name">Name</label>
											<input type="text" name="name" id="name" />
										</div>
										<div class="field half">
											<label for="email">Email</label>
											<input type="text" name="email" id="email" />
										</div>
										<div class="field">
											<label for="message">Message</label>
											<textarea name="message" id="message" rows="4"></textarea>
										</div>
									</div>
									<ul class="actions">
										<li><input type="submit" value="Send Message" class="primary" /></li>
										<li><input type="reset" value="Reset" /></li>
									</ul>
								</form>
								<ul class="icons">
									<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
									<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
									<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
									<li><a href="#" class="icon fa-github"><span class="label">GitHub</span></a></li>
								</ul>
							</article>

						<!-- Elements -->
							<article id="elements">
								<h2 class="major">Elements</h2>

								<section>
									<h3 class="major">Text</h3>
									<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
									This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
									This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
									<hr />
									<h2>Heading Level 2</h2>
									<h3>Heading Level 3</h3>
									<h4>Heading Level 4</h4>
									<h5>Heading Level 5</h5>
									<h6>Heading Level 6</h6>
									<hr />
									<h4>Blockquote</h4>
									<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
									<h4>Preformatted</h4>
									<pre><code>i = 0;

while (!deck.isInOrder()) {
    print 'Iteration ' + i;
    deck.shuffle();
    i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
								</section>

								<section>
									<h3 class="major">Lists</h3>

									<h4>Unordered</h4>
									<ul>
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Alternate</h4>
									<ul class="alt">
										<li>Dolor pulvinar etiam.</li>
										<li>Sagittis adipiscing.</li>
										<li>Felis enim feugiat.</li>
									</ul>

									<h4>Ordered</h4>
									<ol>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis viverra.</li>
										<li>Felis enim feugiat.</li>
										<li>Dolor pulvinar etiam.</li>
										<li>Etiam vel felis lorem.</li>
										<li>Felis enim et feugiat.</li>
									</ol>
									<h4>Icons</h4>
									<ul class="icons">
										<li><a href="#" class="icon fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon fa-facebook"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon fa-github"><span class="label">Github</span></a></li>
									</ul>

									<h4>Actions</h4>
									<ul class="actions">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Table</h3>
									<h4>Default</h4>
									<div class="table-wrapper">
										<table>
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>

									<h4>Alternate</h4>
									<div class="table-wrapper">
										<table class="alt">
											<thead>
												<tr>
													<th>Name</th>
													<th>Description</th>
													<th>Price</th>
												</tr>
											</thead>
											<tbody>
												<tr>
													<td>Item One</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Two</td>
													<td>Vis ac commodo adipiscing arcu aliquet.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Three</td>
													<td> Morbi faucibus arcu accumsan lorem.</td>
													<td>29.99</td>
												</tr>
												<tr>
													<td>Item Four</td>
													<td>Vitae integer tempus condimentum.</td>
													<td>19.99</td>
												</tr>
												<tr>
													<td>Item Five</td>
													<td>Ante turpis integer aliquet porttitor.</td>
													<td>29.99</td>
												</tr>
											</tbody>
											<tfoot>
												<tr>
													<td colspan="2"></td>
													<td>100.00</td>
												</tr>
											</tfoot>
										</table>
									</div>
								</section>

								<section>
									<h3 class="major">Buttons</h3>
									<ul class="actions">
										<li><a href="#" class="button primary">Primary</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button">Default</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
									<ul class="actions">
										<li><a href="#" class="button primary icon fa-download">Icon</a></li>
										<li><a href="#" class="button icon fa-download">Icon</a></li>
									</ul>
									<ul class="actions">
										<li><span class="button primary disabled">Disabled</span></li>
										<li><span class="button disabled">Disabled</span></li>
									</ul>
								</section>

								<section>
									<h3 class="major">Form</h3>
									<form method="post" action="#">
										<div class="fields">
											<div class="field half">
												<label for="demo-name">Name</label>
												<input type="text" name="demo-name" id="demo-name" value="" placeholder="Jane Doe" />
											</div>
											<div class="field half">
												<label for="demo-email">Email</label>
												<input type="email" name="demo-email" id="demo-email" value="" placeholder="jane@untitled.tld" />
											</div>
											<div class="field">
												<label for="demo-category">Category</label>
												<select name="demo-category" id="demo-category">
													<option value="">-</option>
													<option value="1">Manufacturing</option>
													<option value="1">Shipping</option>
													<option value="1">Administration</option>
													<option value="1">Human Resources</option>
												</select>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-low" name="demo-priority" checked>
												<label for="demo-priority-low">Low</label>
											</div>
											<div class="field half">
												<input type="radio" id="demo-priority-high" name="demo-priority">
												<label for="demo-priority-high">High</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-copy" name="demo-copy">
												<label for="demo-copy">Email me a copy</label>
											</div>
											<div class="field half">
												<input type="checkbox" id="demo-human" name="demo-human" checked>
												<label for="demo-human">Not a robot</label>
											</div>
											<div class="field">
												<label for="demo-message">Message</label>
												<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
											</div>
										</div>
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</form>
								</section>

							</article>

					</div>

				<!-- Footer 
					<footer id="footer">
						<p class="copyright">&copy; Untitled. Design: <a href="https://html5up.net">HTML5 UP</a>.</p>
					</footer>-->

			</div>

		<!-- BG -->
			<div id="bg"></div>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>
